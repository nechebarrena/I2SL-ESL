{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "I2SL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLXlw1GNeIVQV2w1egJ26Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nechebarrena/I2SL-ESL/blob/main/I2SL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbbuxoUSgPvG"
      },
      "source": [
        "# Notas del libro An introduction to statistical learning\n",
        "\n",
        "Índice de temas para ver:\n",
        "\n",
        "1. Introducción ---\n",
        "(2.1) - What Is Statistical Learning? \n",
        "(2.2) - Assessing Model Accuracy\n",
        "\n",
        "2. Regresión lineal --- \n",
        "(3.1) - Simple Linear Regression\n",
        "(3.2) - Multiple Linear Regression\n",
        "\n",
        "3. Clasificación ---\n",
        "(4.1) - An Overview of Classification\n",
        "(4.2) - Why Not Linear Regression?\n",
        "(4.3) - Logistic Regression\n",
        "(4.4) - Linear Discriminant Analysis\n",
        "\n",
        "4. Cosas no lineales ---\n",
        "(7.1) - Polynomial Regression\n",
        "\n",
        "5. No supervisado --- \n",
        "(10.1) - The Challenge of Unsupervised Learning\n",
        "(10.2) - Principal Components Analysis\n",
        "(10.3) - Clustering Methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIf5ylH9qnPN"
      },
      "source": [
        "## **1. Introducción**\n",
        "### **(2.1) - What Is Statistical Learning?**\n",
        "\n",
        "Primer ejemplo de un algoritmo que \"aprende\" algo de los datos empíricos.\n",
        "Tenemos un conjunto de observaciones $Y$ que deseamos \"entender\" y otro conjunto de datos  $X_1,X_2,...,X_p$ que creemos explican el comportamiento de $Y$. Podemos suponer que existe un modelo tal que:\n",
        "\n",
        "$Y = f(X) + \\epsilon$\n",
        "\n",
        "donde $f$ es una función desconocida de un conjunto de variables $X_1,X_2,...,X_p$, y $\\epsilon$ es un error aleatorio independiente de $X$ y con media cero (si no fuese cero la podríamos incluir en el modelo).\n",
        "\n",
        "En general decimos que el aprendizaje estadístico es un conjunto de técnicas y herramientas para buscar la $f$ que mejor aproxima al problema y también para poder evaluar cuán buena es esta solución.\n",
        "\n",
        "#### **¿Por qué queremos estimar $f$?**\n",
        "\n",
        "En general podemos pensar en 2 motivos distintos. Estos son predecir e inferir.\n",
        "Cuando usamos un modelo para predecir es porque tenemos un conjunto de mediciones sobre las variables $X_1,X_2,...,X_p$ y queremos conocer cuál es el valor $Y$ asociado. En tal caso podemos pensar que tenemos un modelo $\\hat f$ que aproxima la función desconocida $f$ y que al aplicarlo a los datos obtenemos una predicción $\\hat Y$,\n",
        "\n",
        "$\\hat Y = \\hat f(X)$\n",
        "\n",
        "La predicción que podamos hacer $\\hat Y$ trae consigo 2 errores. El primero que podemos considerar es el error *reducible*. Este error proviene de como ajustamos $\\hat f$ a los datos. Este error se dice reducible porque si mejoramos la técnica podemos mejorar el ajuste. Sin embargo existe un error *irreducible* que antes escribimos como $\\epsilon$. Este error no puede ser eliminado porque forma parte del proceso mismo. En cierta forma lo que decimos con esto es que $Y$ no solo depende de $X_1,X_2,...,X_p$ sino que también depende de $\\epsilon$ de una forma fundamental. La pregunta es, ¿por qué tenemos un error irreducible?... La respuesta más sencilla es porque no conocemos ni podemos medir todas las variables que realmente afectan al proceso. En definitiva es una manifestación del problema del demonio de Laplace. Si pudiésemos conocer y medir tooodas las variables que afectan a un determinado prceso, entonces no tendríamos, a priori, un error irreducible. Pero bueno, esto es obviamente imposible.\n",
        "\n",
        "Podemos escribir el valor de expectación del error cuadrático como:\n",
        "\n",
        "$E[(Y - \\hat Y)^2] = E[(f(x) + \\epsilon - \\hat f(x))^2] = (f(x) - \\hat f(x))^2 + Var(\\epsilon)$\n",
        "\n",
        "donde $(f(x) - \\hat f(x))^2$ es el error reducible y $Var(\\epsilon)$ es el error irreducible. Está claro que el error reducible viene de la diferencia entre el modelo ajustado $\\hat f$ y el modelo desconocido $f$, mientras que el error irreducible proviene del desconocimiento que tenemos del sistema, el cual encapsulamos en $\\epsilon$. En general las técnicas de aprendizaje estadístico buscan minimzar el error reducible.\n",
        "\n",
        "Por otro lado, también podemos buscar un modelo no para hacer predicciones sino para hacer inferencia. En esta situación lo que buscamos es poder entender el fenómeno $f$ y cómo este depende de los features $X_1,X_2,...,X_p$. En general buscamos averiguar cuál es la importancia relativa de cada feature en el resultado final $Y$ y cuáles son las formas funcionales (en el mejor de los casos) de estas dependencias.\n",
        "\n",
        "#### **¿Cómo estimamos $f$?**\n",
        "\n",
        "A lo largo del libro vamos a analizar distintos métodos, lineales y no lineales para aproximar $f$, sin embargo todos comparten ciertas carecterísticas. Por empezar; siempre vamos a considerar que disponemos de $n$ mediciones experimentales (u observaciones directamente) del fenómeno que queremos estudiar. En general podemos separar los métodos (sean lineales o no lineales) en dos categorías, los métodos paramétricos y los no paramétricos.\n",
        "\n",
        "#### **Métodos paramétricos**\n",
        "Los métodos paramétricos son aquellos que asumen inicialmente una forma funcional para la $f$ que vamos a ajustar y permiten ajustar los parámetros de dicha forma funcional para ajustar las predicciones a los datos experimentales. O sea, fijamos inicialmente una forma funcional con una determinada cantidad de parámetros (puede ser aribitrariamente grande) y tratamos de averiguar cuál es el conjunto de ellos que mejor permite ajustar los datos. Un ejemplo muy evidente de este tipo de métodos es un ajuste lineal.\n",
        "\n",
        "$f(X) = \\beta_0 + \\beta_1 x_1 + \\beta_1 x_1 $ \n",
        "$f(X) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ...+ \\beta_p x_p \\approx Y $\n",
        "\n",
        "En este caso la forma funcional de $f$ está prescripta en un modelo lineal, los parámetros que debemos encontrar para que el modelo ajuste lo mejor posible a los datos experimentales $Y$ son los coeficientes $(\\beta_0,\\beta_1,\\beta_2,...\\beta_p)$. \n",
        "\n",
        "#### **Métodos NO paramétricos**\n",
        "\n",
        "Contrariamente a los primeros, los métodos no paramétricos, no definen inicialmente la forma funcional de $f$. Más adelante, cuando veamos algún ejemplo de modelo no paramétrico, probablemente quede más claro cómo funcionan. Ahora, aunque el libro mucho no aclara, yo arriesgo a decir que obviamente estos modelos también tienen parámetros de ajuste, pero a diferencia de los primeros solemos llamarlos hiperparámetros, pues permiten ajustar al modelo pero no lo prescriben. Dicho de otra forma, prescriben el método pero no la forma de $f$. Vuelvo a recordar que estas son mis palabras y no las del libro.\n",
        "Lo que sí dice el libro es que estos métodos suelen ser más propensos al overfit. Esto tiene sentido pues en principio la forma funcional de $f$ puede terminar siendo todo lo complicada que uno permita. Por otro lado, la ventaja que tienen sobre los métodos paramétricos es que pueden ajustar a modelos más complejos de los que uno espera inicialmente.\n",
        "\n",
        "#### **El balance entre la precisión del modelo y su interpretabilidad** \n",
        "\n",
        "A lo largo del libro vamos a analizar una amplia variedad de métodos, paramétricos y no paramétricos, cada uno con cualidades distintas. Estas cualidades terminan redundando en dos características distintas, que en general, se mueven en direcciones opuestas: la flexibilidad del modelo y su interpretabilidad. Un modelo flexible es aquél que permite que la función $f$ varíe más según los datos de entrenamiento. Sin embargo, esta flexibilidad del modelo para buscar $f$ termina redundando en una peor intepretabilidad del mismo. En el extremo opuesto, un modelo menos flexible suele ser más fácil de interpretar. Volvamos al caso del modelo lineal. Este modelo solo permite que $f$ se mueva en el conjunto de las funciones lineales independientemente de cuáles sean los datos de entrenamiento. Esto muestra lo poco flexible que es, sin embargo, su interpretación es bastante directa, porque ya sabemos que cada coeficiente $\\beta_i$ está asociado al comportamiento de la variable $x_i$. \n",
        "\n",
        "En general podemos decir que cuando nuestro objetivo es la inferencia los modelos menos flexibles pero más fáciles de interpretar van a sernos más útiles, mientras que cuando nuestro objetivo está puesto en la predicción podemos recaer en modelos menos interpretables pero más flexibles.\n",
        "\n",
        "#### **Aprendizaje supervisado VS aprendizaje no supervisado**\n",
        "\n",
        "En general los problemas que se nos presenten y que abordemos utilizando técnicas estadísticas pueden venir en dos formas distintas. Por un lado están los problemas donde tenemos un conjunto de mediciones $X$ que podemos identificar como variables  o predictores, y un conjunto de mediciones $Y$ que asociamos a una variable objetivo o target. A estos problemas los atacamos con métodos que llamamos supervisados. Y decimos que son supervisados porque nosotros ajustamos un modelo donde le enseñamos a nuestra $f$ que dado un cierto $X$ responda con un cierto $Y$. Sin embargo existen otro tipo de problemas donde (al menos a priori) no podemos separar entre variables predictoras y variables objetivos. En este caso todas nuestras variables son variables predictoras. Esta situación presenta un problema porque no podemos enseñarle a ninguna función $f$ a que se parezca a ningún valor objetivo $Y$ simplemente porque no lo tenemos. En este caso nuestro objetivo cambia y pasamos a tratar de entender las características de nuestros datos en función de las variables que disponemos. En general intentamos separar nuestros datos según criterios que nos permitan identificar grupos con comportamientos identificables. A estos modelos se los suele llamar de \"clustering\" porque, en resumen, lo que buscan hacer es encontrar clusters de datos en la totalidad de ellos. \n",
        "\n",
        "También existen los problemas semi-supervisados, que son aquellos donde una parte de nuestros datos posee una variable objetivo y otra parte no. De hecho, este es un problema muy común. Sin embargo no lo vamos a abordar en este libro =(.\n",
        "\n",
        "#### **Clasificación VS regresión**\n",
        "\n",
        "Otra posible división que podemos hacer entre nuestros metodos es aquella que separa el tipo de variable que tenemos como objetivo. En general decimos que si nuestra variable objetivo es un valor numérico (continuo) debemos realizar una regresión para poder predecir con nuestro modelo, mientras que si la variable objetivo es categórica, lo que debemos hacer es una clasificación para poder predecir en que categoría caerá una nueva instancia. Sin embargo esta división es muchas veces algo arbitraria y en general los métodos estadísticos sirven para, con leves modificaciones, adaptarse a problemas de clasificación o de regresión.\n",
        "\n",
        "### **(2.1) - Evaluando la precisión del modelo**\n",
        "\n",
        "Existen muchisimos metodos distintos para tratar estadisticamente un conjunto de datos y abordar un problema. Lo que debemos hacer es evaluar, en cada situacion, cual es mejor. Para eso debemos poder calcular metricas que permitan comparar estos modelos y los resultados (cuan buenos o malos son) que producen.\n",
        "\n",
        "#### **Midiendo la calidad del ajuste**\n",
        "\n",
        "En general nuestro objetivo va a ser comparar cuan parecida es una prediccion de nuestro modelo con un dato de la realidad. Cuanto mas parecida sean las predicciones de nuestro modelo a las mediciones experimentales que tenemos mejor sera este. De hecho es la idea mas intuitiva y basica para medir cuan bueno es un modelo que aproxima (o intenta) a la realidad.\n",
        "\n",
        "Para modelos donde se intenta realizar una regresion a valores numericos una de las metricas mas utilizadas es el error cuadratico medio o Mean Squared Error (MSE). Como su nombre indica, MSE es el valor medio de los errores (diferencias) al cuadrado, o sea:\n",
        "\n",
        "$MSE= \\dfrac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat f(x_i))^2$\n",
        "\n",
        "En este caso $y_i$ es el valor medido $i$-esimo y $\\hat f(x_i)$ la prediccion de nuestro modelo para ese mismo dato segun el predictor $x_i$. Realizamos esta diferencia para los $n$ puntos (mediciones), cada una la elevamos al cuadrado y le calculamos el promedio. Queda claro que cuanto mas grande sean las diferencias entre los puntos medidos y nuestro modelo mayor sera el valor del MSE.\n",
        "\n",
        "Una pregunta que cabe hacerse es sobre que datos calcular el MSE. La primer respuesta es hacerlo sobre todos los datos. O sea, sobre los datos que se utilizaron para encontrar el modelo. A la metrica asi calculada se la llama MSE train, pues esta calculada sobre los datos de train. Otra posibilidad es dejar un conjunto de datos de testeo fuera del entrenamiento y calcular el MSE sobre estos, o sea, el MSE test. La siguiente pregunta es si estas dos metricas dan o deberian dar lo mismo. La respuesta es que no (en general) y de esta diferencia, ademas, podemos sacar informacion.\n",
        "\n",
        "Si un modelo es muy flexible y tiene capacidad de ajustar muchos parametros es posible que tenga un MSE train muy chico. Sin embargo el MSE test para este modelo puede ser muy grande. De forma contraria, si el modelo es muy poco flexible y no puede \"aprender\" el modelo subyacente a los datos, puede tener un MSE train muy grande. Pero en este caso seria esperable que el MSE test tambien lo sea. En el medio de estas dos posibilidades debe existir un modelo con la flexibildad adecuada para aprender el modelo mas parecido al modelo real. En este caso esperamos obtener 2 cosas. La primera es el MSE test mas bajo posible y la segunda es que la diferencia entre este y el MSE train sea tambien la mas chica posible. En este caso hablariamos de nuestro modelo optimo. \n",
        "\n",
        "De aca podemos sacar algunas conclusiones. El caso donde tenemos un MSE train bajo pero un MSE test alto decimos que tenemos overfitting. Cuando ambos errores son altos decimos que tenemos underfitting. Ademas podemos decir, si recordamos el valor de expectacion para la diferencia cuadratica, que existe un error minimo irreducible que es la varianza de $\\epsilon$. Este error provenia de todas aquellas variables que interactuan con nuestro sistema pero que no incluimos en el modelo. Este error es lo minimo que podemos esperar en el MSE test. O sea, nunca podemos tener un modelo, que sobre datos desconocido, obtiene un error menor a este (en terminos estadisticos claro).\n",
        "\n",
        "#### **El compromiso entre el Bias y la Varianza**\n",
        "\n",
        "El error esperable cometido sobre el conjunto de test lo podemos escribir como:\n",
        "\n",
        "$E(y_0 - \\hat f(x_0))^2 = Var(\\hat f(x_0)) + (Bias(\\hat f(x_0)))^2 + Var(\\epsilon) $.\n",
        "\n",
        "(El libro no desarrolla esta cuenta. Buscarla y desarrollarla como tarea.)\n",
        "\n",
        "En este caso la esperanza calculada para un modelo $\\hat f$ indica que estamos considerando un monton de realizaciones de este modelo sobre distintos datos de entrenamiento. Pongamos un ejemplo. Supongamos que nuestro modelo $\\hat f$ corresponde a un ajuste lineal. Si realizamos un monton de ajustes lineales sobre distintos datos de entrenamiento obtendremos un monton de modelos distintos, todos lineales, pero con distintos parametros. La varianza sobre estos modelos $Var(\\hat f(x_0))$ nos indica cuan diferentes seran entre si. Mucha varianza significa modelos muy distintos (en el caso de nuestro modelo lineal significa valores muy distintos en los coeficientes). Por otro lado, el bias sobre ellos $Bias(\\hat f(x_0))$ indica cuan lejos estan estos modelos de aproximar al modelo subyacente. \n",
        "\n",
        "Idealmente uno busca un modelo que tenga el menor Bias y la menor Varianza, esto redunda en el menor error MSE test. Sin embargo el Bias y la Varianza tienen comportamientos opuestos, por lo cual minimzar el MSE test en realidad significa encontrar el punto optimo entre el Bias y la Varianza. Por eso en general hablamos del \"compromiso\" entre ambos.\n",
        "\n",
        "Es general cuando un modelo aumenta su complejidad (flexibilidad) aumenta su varianza. Esto es facil de entender pues al permitirle mayor flexibilidad a la hora de copiar los datos, ante el cambio de ellos, tambien cambiara el modelo. Por el contrario, cuando el modelo es las flexible su Bias tiene a decrecer. Esto tambien resulta intuitivo, pues al permitir modelos mas complejos incluimos el modelo subyacente dentro del espacio de posibles modelos. \n",
        "\n",
        "Los mismos razonamientos valen para el otro lado. En un modelo simple permitimos poca Varianza entre ellos mientras que probablemente no incluyamos al modelo subyacente, con lo cual aumentamos el Bias.\n",
        "\n",
        "Encontrar el punto optimo donde se minimza el MSE test es en general el principal objetivo al armar un modelo estadistico y buena parte del libro esta centrada en esto.\n",
        "\n",
        "\n"
      ]
    }
  ]
}